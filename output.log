2023-10-22 17:58:11 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-22 17:58:11 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-22 17:58:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders'],
 'USER_AGENT': ''}
2023-10-22 17:58:11 [py.warnings] WARNING: C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-22 17:58:11 [scrapy.extensions.telnet] INFO: Telnet Password: 9b5c7671d9d6f1cb
2023-10-22 17:58:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-22 17:58:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-22 17:58:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-22 17:58:11 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-22 17:58:11 [scrapy.core.engine] INFO: Spider opened
2023-10-22 17:58:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-22 17:58:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-22 17:58:13 [tldextract.cache] WARNING: unable to cache publicsuffix.org-tlds.{'urls': ('https://publicsuffix.org/list/public_suffix_list.dat', 'https://raw.githubusercontent.com/publicsuffix/list/master/public_suffix_list.dat'), 'fallback_to_snapshot': True} in C:\ProgramData\anaconda3\Lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json. This could refresh the Public Suffix List over HTTP every app startup. Construct your `TLDExtract` with a writable `cache_dir` or set `cache_dir=False` to silence this warning. [WinError 5] Access is denied: 'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tldextract\\.suffix_cache'
2023-10-22 17:58:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=8> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=3> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=5> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=4> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=7> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=9> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=6> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=2> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=10> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=13> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=12> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=17> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=15> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=16> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=11> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=14> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=18> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=22> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=19> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=20> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=24> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=23> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=21> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=25> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=26> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=29> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=32> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=30> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=34> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=31> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=27> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=33> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=28> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=35> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=36> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=38> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=39> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=42> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=41> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=40> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=43> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=37> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=47> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=46> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=50> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=45> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=49> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=44> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=48> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:23 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-22 17:58:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 17269,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 3934665,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 11.257016,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 23, 0, 58, 23, 124289),
 'httpcompression/response_bytes': 18085934,
 'httpcompression/response_count': 50,
 'log_count/ERROR': 50,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'spider_exceptions/AttributeError': 50,
 'start_time': datetime.datetime(2023, 10, 23, 0, 58, 11, 867273)}
2023-10-22 17:58:23 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-22 17:58:25 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-22 17:58:25 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-22 17:58:25 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders'],
 'USER_AGENT': ''}
2023-10-22 17:58:25 [py.warnings] WARNING: C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-22 17:58:25 [scrapy.extensions.telnet] INFO: Telnet Password: eeeb5dc40f7e5543
2023-10-22 17:58:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-22 17:58:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-22 17:58:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-22 17:58:25 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-22 17:58:25 [scrapy.core.engine] INFO: Spider opened
2023-10-22 17:58:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-22 17:58:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-22 17:58:26 [tldextract.cache] WARNING: unable to cache publicsuffix.org-tlds.{'urls': ('https://publicsuffix.org/list/public_suffix_list.dat', 'https://raw.githubusercontent.com/publicsuffix/list/master/public_suffix_list.dat'), 'fallback_to_snapshot': True} in C:\ProgramData\anaconda3\Lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json. This could refresh the Public Suffix List over HTTP every app startup. Construct your `TLDExtract` with a writable `cache_dir` or set `cache_dir=False` to silence this warning. [WinError 5] Access is denied: 'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tldextract\\.suffix_cache'
2023-10-22 17:58:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=6> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=4> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=8> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=2> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=5> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=3> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=7> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=9> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=10> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=14> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=11> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=15> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=12> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=16> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=13> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=17> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=18> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=19> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=22> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=20> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=21> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=23> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=26> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=24> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=28> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=27> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=30> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=25> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=29> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=31> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=32> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=36> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=35> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=33> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=38> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=34> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=37> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=39> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=40> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=42> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=44> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=43> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=46> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=45> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=41> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=48> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=47> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=49> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=50> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:36 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-22 17:58:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 17249,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 3932517,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 10.194672,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 23, 0, 58, 36, 65623),
 'httpcompression/response_bytes': 18083233,
 'httpcompression/response_count': 50,
 'log_count/ERROR': 50,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'spider_exceptions/AttributeError': 50,
 'start_time': datetime.datetime(2023, 10, 23, 0, 58, 25, 870951)}
2023-10-22 17:58:36 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-22 17:58:53 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-22 17:58:53 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-22 17:58:53 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders'],
 'USER_AGENT': '11'}
2023-10-22 17:58:53 [py.warnings] WARNING: C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-22 17:58:53 [scrapy.extensions.telnet] INFO: Telnet Password: 16111dc3457c0eb2
2023-10-22 17:58:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-22 17:58:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-22 17:58:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-22 17:58:53 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-22 17:58:53 [scrapy.core.engine] INFO: Spider opened
2023-10-22 17:58:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-22 17:58:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-22 17:58:55 [tldextract.cache] WARNING: unable to cache publicsuffix.org-tlds.{'urls': ('https://publicsuffix.org/list/public_suffix_list.dat', 'https://raw.githubusercontent.com/publicsuffix/list/master/public_suffix_list.dat'), 'fallback_to_snapshot': True} in C:\ProgramData\anaconda3\Lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json. This could refresh the Public Suffix List over HTTP every app startup. Construct your `TLDExtract` with a writable `cache_dir` or set `cache_dir=False` to silence this warning. [WinError 5] Access is denied: 'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tldextract\\.suffix_cache'
2023-10-22 17:58:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=8> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=5> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=7> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=3> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=6> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:58:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=4> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=9> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=2> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=10> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=13> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=15> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=11> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=14> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=12> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=16> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=17> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=19> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=21> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=22> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=20> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=23> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=18> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=28> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=24> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=26> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=27> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=29> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=25> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=30> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=31> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=32> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=38> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=34> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=37> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=35> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=36> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=33> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=39> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=40> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=42> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=45> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=47> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=46> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=41> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=43> (referer: None)
Traceback (most recent call last):
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Hudong\Desktop\scrapy-pyqt5\scraps\scraps\spiders\book.py", line 23, in parse
    items['review'] = review.split(' ')[-1]
                      ^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'split'
2023-10-22 17:59:20 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-22 17:59:20 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-22 17:59:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders'],
 'USER_AGENT': ''}
2023-10-22 17:59:20 [py.warnings] WARNING: C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-22 17:59:20 [scrapy.extensions.telnet] INFO: Telnet Password: 54552a52c6ff65e7
2023-10-22 17:59:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-22 17:59:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-22 17:59:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-22 17:59:20 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-22 17:59:20 [scrapy.core.engine] INFO: Spider opened
2023-10-22 17:59:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-22 17:59:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-22 18:01:18 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-22 18:01:18 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-22 18:01:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders'],
 'USER_AGENT': ''}
2023-10-22 18:01:18 [py.warnings] WARNING: C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-22 18:01:18 [scrapy.extensions.telnet] INFO: Telnet Password: 6c9f34180780b806
2023-10-22 18:01:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-22 18:01:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-22 18:01:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-22 18:01:18 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-22 18:01:18 [scrapy.core.engine] INFO: Spider opened
2023-10-22 18:01:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-22 18:01:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-22 18:01:21 [tldextract.cache] WARNING: unable to cache publicsuffix.org-tlds.{'urls': ('https://publicsuffix.org/list/public_suffix_list.dat', 'https://raw.githubusercontent.com/publicsuffix/list/master/public_suffix_list.dat'), 'fallback_to_snapshot': True} in C:\ProgramData\anaconda3\Lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json. This could refresh the Public Suffix List over HTTP every app startup. Construct your `TLDExtract` with a writable `cache_dir` or set `cache_dir=False` to silence this warning. [WinError 5] Access is denied: 'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tldextract\\.suffix_cache'
2023-10-22 18:01:26 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-22 18:01:26 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-22 18:01:26 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders'],
 'USER_AGENT': 'ff'}
2023-10-22 18:01:26 [py.warnings] WARNING: C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-22 18:01:26 [scrapy.extensions.telnet] INFO: Telnet Password: 7728fde1c686152e
2023-10-22 18:01:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-22 18:01:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-22 18:01:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-22 18:01:26 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-22 18:01:26 [scrapy.core.engine] INFO: Spider opened
2023-10-22 18:01:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-22 18:01:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-22 18:01:27 [tldextract.cache] WARNING: unable to cache publicsuffix.org-tlds.{'urls': ('https://publicsuffix.org/list/public_suffix_list.dat', 'https://raw.githubusercontent.com/publicsuffix/list/master/public_suffix_list.dat'), 'fallback_to_snapshot': True} in C:\ProgramData\anaconda3\Lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json. This could refresh the Public Suffix List over HTTP every app startup. Construct your `TLDExtract` with a writable `cache_dir` or set `cache_dir=False` to silence this warning. [WinError 5] Access is denied: 'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tldextract\\.suffix_cache'
2023-10-22 18:04:02 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-22 18:04:02 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-22 18:04:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders'],
 'USER_AGENT': ''}
2023-10-22 18:04:02 [py.warnings] WARNING: C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-22 18:04:02 [scrapy.extensions.telnet] INFO: Telnet Password: 7ac2cb01b2926e75
2023-10-22 18:04:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-22 18:04:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-22 18:04:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-22 18:04:02 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-22 18:04:02 [scrapy.core.engine] INFO: Spider opened
2023-10-22 18:04:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-22 18:04:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-22 18:04:04 [tldextract.cache] WARNING: unable to cache publicsuffix.org-tlds.{'urls': ('https://publicsuffix.org/list/public_suffix_list.dat', 'https://raw.githubusercontent.com/publicsuffix/list/master/public_suffix_list.dat'), 'fallback_to_snapshot': True} in C:\ProgramData\anaconda3\Lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json. This could refresh the Public Suffix List over HTTP every app startup. Construct your `TLDExtract` with a writable `cache_dir` or set `cache_dir=False` to silence this warning. [WinError 5] Access is denied: 'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tldextract\\.suffix_cache'
2023-10-22 18:04:15 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-22 18:04:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 17092,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 3937127,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 13.118511,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 23, 1, 4, 15, 626704),
 'httpcompression/response_bytes': 18096335,
 'httpcompression/response_count': 50,
 'item_scraped_count': 500,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2023, 10, 23, 1, 4, 2, 508193)}
2023-10-22 18:04:15 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-22 18:33:49 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-22 18:33:49 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-22 18:33:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders'],
 'USER_AGENT': ''}
2023-10-22 18:33:49 [py.warnings] WARNING: C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-22 18:33:49 [scrapy.extensions.telnet] INFO: Telnet Password: d82c551d182cbe3d
2023-10-22 18:33:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-22 18:33:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-22 18:33:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-22 18:33:49 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-22 18:33:49 [scrapy.core.engine] INFO: Spider opened
2023-10-22 18:33:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-22 18:33:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-22 18:33:50 [tldextract.cache] WARNING: unable to cache publicsuffix.org-tlds.{'urls': ('https://publicsuffix.org/list/public_suffix_list.dat', 'https://raw.githubusercontent.com/publicsuffix/list/master/public_suffix_list.dat'), 'fallback_to_snapshot': True} in C:\ProgramData\anaconda3\Lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json. This could refresh the Public Suffix List over HTTP every app startup. Construct your `TLDExtract` with a writable `cache_dir` or set `cache_dir=False` to silence this warning. [WinError 5] Access is denied: 'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tldextract\\.suffix_cache'
2023-10-22 18:34:01 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-22 18:34:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 17108,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 3952542,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 12.631892,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 23, 1, 34, 1, 991556),
 'httpcompression/response_bytes': 18116370,
 'httpcompression/response_count': 50,
 'item_scraped_count': 500,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2023, 10, 23, 1, 33, 49, 359664)}
2023-10-22 18:34:01 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-22 18:34:09 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-22 18:34:09 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-22 18:34:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders'],
 'USER_AGENT': ''}
2023-10-22 18:34:09 [py.warnings] WARNING: C:\ProgramData\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-22 18:34:09 [scrapy.extensions.telnet] INFO: Telnet Password: 986d7f3d4ced0cd0
2023-10-22 18:34:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-22 18:34:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-22 18:34:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-22 18:34:09 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-22 18:34:09 [scrapy.core.engine] INFO: Spider opened
2023-10-22 18:34:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-22 18:34:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-22 18:34:10 [tldextract.cache] WARNING: unable to cache publicsuffix.org-tlds.{'urls': ('https://publicsuffix.org/list/public_suffix_list.dat', 'https://raw.githubusercontent.com/publicsuffix/list/master/public_suffix_list.dat'), 'fallback_to_snapshot': True} in C:\ProgramData\anaconda3\Lib\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json. This could refresh the Public Suffix List over HTTP every app startup. Construct your `TLDExtract` with a writable `cache_dir` or set `cache_dir=False` to silence this warning. [WinError 5] Access is denied: 'C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tldextract\\.suffix_cache'
2023-10-22 18:34:20 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-22 18:34:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 17224,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 3951674,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 11.07249,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 23, 1, 34, 20, 541469),
 'httpcompression/response_bytes': 18116581,
 'httpcompression/response_count': 50,
 'item_scraped_count': 500,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2023, 10, 23, 1, 34, 9, 468979)}
2023-10-22 18:34:20 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-23 23:27:25 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-23 23:27:25 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-23 23:27:25 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-23 23:27:25 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-23 23:27:25 [scrapy.extensions.telnet] INFO: Telnet Password: a03e9462d9653945
2023-10-23 23:27:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-23 23:27:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-23 23:27:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-23 23:27:25 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-23 23:27:25 [scrapy.core.engine] INFO: Spider opened
2023-10-23 23:27:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-23 23:27:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-23 23:28:33 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-23 23:28:33 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-23 23:28:33 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-23 23:28:33 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-23 23:28:33 [scrapy.extensions.telnet] INFO: Telnet Password: d42157d56822e353
2023-10-23 23:28:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-23 23:28:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-23 23:28:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-23 23:28:33 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-23 23:28:33 [scrapy.core.engine] INFO: Spider opened
2023-10-23 23:28:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-23 23:28:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-23 23:29:33 [scrapy.extensions.logstats] INFO: Crawled 30 pages (at 30 pages/min), scraped 290 items (at 290 items/min)
2023-10-23 23:29:53 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-23 23:29:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 20595,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 3938374,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 80.059072,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 23, 23, 29, 53, 184323),
 'httpcompression/response_bytes': 18286442,
 'httpcompression/response_count': 50,
 'item_scraped_count': 500,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2023, 10, 23, 23, 28, 33, 125251)}
2023-10-23 23:29:53 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-23 23:33:09 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-23 23:33:09 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-23 23:33:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-23 23:33:09 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-23 23:33:09 [scrapy.extensions.telnet] INFO: Telnet Password: 1a3d5ce2b3f45252
2023-10-23 23:33:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-23 23:33:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-23 23:33:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-23 23:33:09 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-23 23:33:09 [scrapy.core.engine] INFO: Spider opened
2023-10-23 23:33:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-23 23:33:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-23 23:33:13 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-23 23:33:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 618,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 79366,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 3.662685,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 23, 23, 33, 13, 364840),
 'httpcompression/response_bytes': 354915,
 'httpcompression/response_count': 1,
 'item_scraped_count': 10,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2023, 10, 23, 23, 33, 9, 702155)}
2023-10-23 23:33:13 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-24 01:22:37 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 01:22:37 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 01:22:37 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 01:22:37 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 01:22:37 [scrapy.extensions.telnet] INFO: Telnet Password: 97f19cafc5a34e66
2023-10-24 01:22:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 01:22:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 01:22:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 01:22:37 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 01:22:37 [scrapy.core.engine] INFO: Spider opened
2023-10-24 01:22:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:22:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 01:42:06 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 1 items (at 1 items/min)
2023-10-24 01:48:13 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 01:48:13 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 01:48:13 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 01:48:13 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 01:48:13 [scrapy.extensions.telnet] INFO: Telnet Password: 0ef9d5e3c3c939d1
2023-10-24 01:48:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 01:48:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 01:48:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 01:48:13 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 01:48:13 [scrapy.core.engine] INFO: Spider opened
2023-10-24 01:48:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:48:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 01:48:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=6> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:48:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=2> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:48:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=3> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=4> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=8> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:13 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:49:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=7> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=10> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=13> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=11> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=5> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=12> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=9> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=17> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=14> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:49:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=16> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:50:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=15> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:50:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=19> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:50:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=18> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:50:13 [scrapy.extensions.logstats] INFO: Crawled 20 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=26> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:50:39 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 01:50:39 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 01:50:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 01:50:39 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 01:50:39 [scrapy.extensions.telnet] INFO: Telnet Password: 4c3e4da91c3e6bfb
2023-10-24 01:50:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 01:50:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 01:50:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 01:50:39 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 01:50:39 [scrapy.core.engine] INFO: Spider opened
2023-10-24 01:50:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:50:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 01:51:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=8> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:51:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:51:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=10> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:51:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=7> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:51:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=4> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:51:39 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:51:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=12> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies']['name']
                              ~~~~~~~~~~~~~~~~^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=5> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
                              ^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:52:39 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=14> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
                              ^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=15> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
                              ^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=16> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
                              ^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=13> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
                              ^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=9> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
                              ^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=6> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
                              ^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=11> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
                              ^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-10-24 01:53:02 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 01:53:02 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 01:53:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 01:53:02 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 01:53:02 [scrapy.extensions.telnet] INFO: Telnet Password: 1efd2404680fa838
2023-10-24 01:53:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 01:53:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 01:53:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 01:53:02 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 01:53:02 [scrapy.core.engine] INFO: Spider opened
2023-10-24 01:53:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:53:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 01:53:50 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 01:53:50 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 01:53:50 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 01:53:50 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 01:53:50 [scrapy.extensions.telnet] INFO: Telnet Password: 7b2199a09209ec1d
2023-10-24 01:53:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 01:53:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 01:53:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 01:53:50 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 01:53:50 [scrapy.core.engine] INFO: Spider opened
2023-10-24 01:53:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:53:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 01:55:04 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 01:55:04 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 01:55:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 01:55:04 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 01:55:04 [scrapy.extensions.telnet] INFO: Telnet Password: 6fc0fb1af9d51637
2023-10-24 01:55:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 01:55:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 01:55:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 01:55:04 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 01:55:04 [scrapy.core.engine] INFO: Spider opened
2023-10-24 01:55:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:55:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 01:56:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=6> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
    ~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\item.py", line 85, in __setitem__
    raise KeyError(f"{self.__class__.__name__} does not support field: {key}")
KeyError: 'scrapsItem does not support field: agency_company'
2023-10-24 01:56:09 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:57:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=4> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
    ~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\item.py", line 85, in __setitem__
    raise KeyError(f"{self.__class__.__name__} does not support field: {key}")
KeyError: 'scrapsItem does not support field: agency_company'
2023-10-24 01:57:07 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:57:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
    ~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\item.py", line 85, in __setitem__
    raise KeyError(f"{self.__class__.__name__} does not support field: {key}")
KeyError: 'scrapsItem does not support field: agency_company'
2023-10-24 01:57:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=9> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
    ~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\item.py", line 85, in __setitem__
    raise KeyError(f"{self.__class__.__name__} does not support field: {key}")
KeyError: 'scrapsItem does not support field: agency_company'
2023-10-24 01:57:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=3> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
    ~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\item.py", line 85, in __setitem__
    raise KeyError(f"{self.__class__.__name__} does not support field: {key}")
KeyError: 'scrapsItem does not support field: agency_company'
2023-10-24 01:57:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=2> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
    ~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\item.py", line 85, in __setitem__
    raise KeyError(f"{self.__class__.__name__} does not support field: {key}")
KeyError: 'scrapsItem does not support field: agency_company'
2023-10-24 01:57:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=7> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
    ~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\item.py", line 85, in __setitem__
    raise KeyError(f"{self.__class__.__name__} does not support field: {key}")
KeyError: 'scrapsItem does not support field: agency_company'
2023-10-24 01:57:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=5> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
    ~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\item.py", line 85, in __setitem__
    raise KeyError(f"{self.__class__.__name__} does not support field: {key}")
KeyError: 'scrapsItem does not support field: agency_company'
2023-10-24 01:57:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=8> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
    ~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\item.py", line 85, in __setitem__
    raise KeyError(f"{self.__class__.__name__} does not support field: {key}")
KeyError: 'scrapsItem does not support field: agency_company'
2023-10-24 01:57:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=10> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 38, in parse
    items['agency_company'] = item['agencies'][0]['name']
    ~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\item.py", line 85, in __setitem__
    raise KeyError(f"{self.__class__.__name__} does not support field: {key}")
KeyError: 'scrapsItem does not support field: agency_company'
2023-10-24 01:57:39 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 01:57:39 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 01:57:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 01:57:39 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 01:57:39 [scrapy.extensions.telnet] INFO: Telnet Password: 6ea2c6cfb41aff55
2023-10-24 01:57:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 01:57:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 01:57:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 01:57:39 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 01:57:39 [scrapy.core.engine] INFO: Spider opened
2023-10-24 01:57:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:57:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 01:58:56 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 01:58:56 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 01:58:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 01:58:56 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 01:58:56 [scrapy.extensions.telnet] INFO: Telnet Password: 589c824d0a5c582f
2023-10-24 01:58:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 01:58:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 01:58:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 01:58:56 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 01:58:56 [scrapy.core.engine] INFO: Spider opened
2023-10-24 01:58:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 01:58:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 02:02:06 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 02:02:06 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 02:02:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 02:02:06 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 02:02:06 [scrapy.extensions.telnet] INFO: Telnet Password: d4a775acd308502d
2023-10-24 02:02:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 02:02:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 02:02:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 02:02:06 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 02:02:06 [scrapy.core.engine] INFO: Spider opened
2023-10-24 02:02:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:02:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 02:02:35 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 02:02:35 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 02:02:35 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 02:02:35 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 02:02:35 [scrapy.extensions.telnet] INFO: Telnet Password: a1439efaf433ec0a
2023-10-24 02:02:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 02:02:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 02:02:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 02:02:35 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 02:02:35 [scrapy.core.engine] INFO: Spider opened
2023-10-24 02:02:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:02:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2023-10-24 02:03:06 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:03:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=3> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:03:35 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:03:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=10> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:03:43 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 02:03:43 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 02:03:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 02:03:43 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 02:03:43 [scrapy.extensions.telnet] INFO: Telnet Password: 3b96fa9767c6704d
2023-10-24 02:03:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 02:03:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 02:03:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 02:03:43 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 02:03:43 [scrapy.core.engine] INFO: Spider opened
2023-10-24 02:03:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:03:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2023-10-24 02:03:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=12> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:03:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:06 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:04:10 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 02:04:10 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 02:04:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 02:04:10 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 02:04:10 [scrapy.extensions.telnet] INFO: Telnet Password: 4d18c6b9a212e161
2023-10-24 02:04:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 02:04:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 02:04:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 02:04:10 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 02:04:10 [scrapy.core.engine] INFO: Spider opened
2023-10-24 02:04:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:04:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2023-10-24 02:04:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=2> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=7> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:47 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=11. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2023-10-24 02:04:47 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=9. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2023-10-24 02:04:47 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=17. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2023-10-24 02:04:47 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=5. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2023-10-24 02:04:47 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=14. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2023-10-24 02:04:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=18> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=21> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=22> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=20> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=16> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=15> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=19> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=13> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=6> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=11> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=14> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=17> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=8> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=4> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=9> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=23> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=5> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=24> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=26> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=27> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=25> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=28> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=29> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=31> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=30> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=32> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=34> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=35> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=37> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=33> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=38> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=39> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=36> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=41> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=40> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=42> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=43> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=44> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=45> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=46> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=47> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=48> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=49> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&page=50> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:56 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-24 02:04:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method scrapspider.close of <scrapspider 'scraps' at 0x28373c8c7d0>>
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 312, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 55, in close
    spider.Q.put('')
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:04:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 17,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 5,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 12,
 'downloader/request_bytes': 26083,
 'downloader/request_count': 68,
 'downloader/request_method_count/GET': 68,
 'downloader/response_bytes': 3936049,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 169.65009,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 24, 2, 4, 56, 252219),
 'httpcompression/response_bytes': 17994885,
 'httpcompression/response_count': 50,
 'log_count/ERROR': 51,
 'log_count/INFO': 12,
 'log_count/WARNING': 6,
 'response_received_count': 51,
 'retry/count': 17,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 5,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 12,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 67,
 'scheduler/dequeued/memory': 67,
 'scheduler/enqueued': 67,
 'scheduler/enqueued/memory': 67,
 'spider_exceptions/FileNotFoundError': 50,
 'start_time': datetime.datetime(2023, 10, 24, 2, 2, 6, 602129)}
2023-10-24 02:04:56 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-24 02:05:15 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 1 items (at 1 items/min)
2023-10-24 02:05:23 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-24 02:05:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 7,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 7,
 'downloader/request_bytes': 22059,
 'downloader/request_count': 58,
 'downloader/request_method_count/GET': 58,
 'downloader/response_bytes': 3940135,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 73.337621,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 24, 2, 5, 23, 909371),
 'httpcompression/response_bytes': 18014876,
 'httpcompression/response_count': 50,
 'item_scraped_count': 500,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 48,
 'request_depth_max': 1,
 'response_received_count': 51,
 'retry/count': 7,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 7,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 57,
 'scheduler/dequeued/memory': 57,
 'scheduler/enqueued': 57,
 'scheduler/enqueued/memory': 57,
 'start_time': datetime.datetime(2023, 10, 24, 2, 4, 10, 571750)}
2023-10-24 02:05:23 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-24 02:50:15 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 02:50:15 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 02:50:15 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 02:50:15 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 02:50:15 [scrapy.extensions.telnet] INFO: Telnet Password: 2b55b3a10beac79e
2023-10-24 02:50:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 02:50:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 02:50:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 02:50:15 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 02:50:15 [scrapy.core.engine] INFO: Spider opened
2023-10-24 02:50:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:50:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 02:50:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&propertyTypes=land-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting&tenure=vacant&maxPrice=150000&minPrice=35000&maxFloorArea=2000&minFloorArea=250&maxSiteArea=10000&minSiteArea=200&numParkingSpaces=1&energyEfficiency=1&keywords=factory%2Bshop&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:50:28 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-24 02:50:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 34957,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 2840838,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 13.434935,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 24, 2, 50, 28, 664032),
 'httpcompression/response_bytes': 9351115,
 'httpcompression/response_count': 50,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2023, 10, 24, 2, 50, 15, 229097)}
2023-10-24 02:50:28 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-24 02:50:48 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 02:50:48 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 02:50:48 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 02:50:48 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 02:50:48 [scrapy.extensions.telnet] INFO: Telnet Password: 8d681800b23e4a72
2023-10-24 02:50:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 02:50:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 02:50:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 02:50:48 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 02:50:48 [scrapy.core.engine] INFO: Spider opened
2023-10-24 02:50:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:50:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 02:50:57 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 02:50:57 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 02:50:57 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 02:50:57 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 02:50:57 [scrapy.extensions.telnet] INFO: Telnet Password: 9c50c2a7dbef01af
2023-10-24 02:50:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 02:50:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 02:50:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 02:50:57 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 02:50:57 [scrapy.core.engine] INFO: Spider opened
2023-10-24 02:50:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:50:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 02:51:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&propertyTypes=land-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting&tenure=vacant&maxPrice=150000&minPrice=35000&maxFloorArea=2000&minFloorArea=250&maxSiteArea=10000&minSiteArea=200&numParkingSpaces=1&energyEfficiency=1&keywords=factory&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:51:11 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-24 02:51:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 34603,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 2839029,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 13.885398,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 24, 2, 51, 11, 126514),
 'httpcompression/response_bytes': 9338333,
 'httpcompression/response_count': 50,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2023, 10, 24, 2, 50, 57, 241116)}
2023-10-24 02:51:11 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-24 02:51:19 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 02:51:19 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 02:51:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 02:51:19 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 02:51:19 [scrapy.extensions.telnet] INFO: Telnet Password: 81e53762eadb2501
2023-10-24 02:51:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 02:51:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 02:51:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 02:51:19 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 02:51:19 [scrapy.core.engine] INFO: Spider opened
2023-10-24 02:51:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:51:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 02:51:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&propertyTypes=land-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting&tenure=vacant&maxPrice=1000000&numParkingSpaces=1&energyEfficiency=1&keywords=factory&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:51:35 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-24 02:51:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 30456,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 2839072,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 16.002299,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 24, 2, 51, 35, 645678),
 'httpcompression/response_bytes': 9338119,
 'httpcompression/response_count': 50,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2023, 10, 24, 2, 51, 19, 643379)}
2023-10-24 02:51:35 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-24 02:51:58 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 02:51:58 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 02:51:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 02:51:58 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 02:51:58 [scrapy.extensions.telnet] INFO: Telnet Password: 8bffe712f76b64c3
2023-10-24 02:51:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 02:51:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 02:51:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 02:51:58 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 02:51:58 [scrapy.core.engine] INFO: Spider opened
2023-10-24 02:51:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:51:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 02:52:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting&numParkingSpaces=1&energyEfficiency=1&page=6> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:52:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting&numParkingSpaces=1&energyEfficiency=1&page=2> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:52:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting&numParkingSpaces=1&energyEfficiency=1&page=5> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:52:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting&numParkingSpaces=1&energyEfficiency=1&page=3> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:52:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting&numParkingSpaces=1&energyEfficiency=1&page=4> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:52:12 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-24 02:52:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 29428,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 2998434,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 14.283853,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 24, 2, 52, 12, 943884),
 'httpcompression/response_bytes': 10854209,
 'httpcompression/response_count': 50,
 'item_scraped_count': 16,
 'log_count/ERROR': 5,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 1,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'spider_exceptions/KeyError': 5,
 'start_time': datetime.datetime(2023, 10, 24, 2, 51, 58, 660031)}
2023-10-24 02:52:12 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-24 02:52:26 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 02:52:26 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 02:52:26 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 02:52:26 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 02:52:26 [scrapy.extensions.telnet] INFO: Telnet Password: 688f2bdc53f49ba6
2023-10-24 02:52:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 02:52:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 02:52:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 02:52:26 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 02:52:26 [scrapy.core.engine] INFO: Spider opened
2023-10-24 02:52:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:52:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 02:52:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 311, in _recv_bytes
    nread, err = ov.GetOverlappedResult(True)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [WinError 109] The pipe has been ended

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 507, in Client
    answer_challenge(c, authkey)
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 751, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 215, in recv_bytes
    buf = self._recv_bytes(maxlength)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 320, in _recv_bytes
    raise EOFError
EOFError
2023-10-24 02:52:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=3> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=5> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=9> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=4> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=7> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=8> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=2> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=6> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=11> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=10> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=12> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=15> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=13> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=17> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=16> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=14> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=18> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=19> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=20> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=21> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=22> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=23> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=24> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=25> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=26> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=27> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=28> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=29> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=30> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=32> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=31> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=33> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=34> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=35> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=36> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=37> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=41> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=40> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=38> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=39> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=42> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=43> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=44> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=45> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=47> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=49> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=46> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=50> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Ccommercial-farming%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods%2Cmedical-consulting%2Cother&page=48> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 45, in parse
    self.Q.put(items)
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
        ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:40 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-24 02:52:40 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method scrapspider.close of <scrapspider 'scraps' at 0x16df173d290>>
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 814, in _callmethod
    conn = self._tls.connection
           ^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ForkAwareLocal' object has no attribute 'connection'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 312, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 55, in close
    spider.Q.put('')
  File "<string>", line 2, in put
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 818, in _callmethod
    self._connect()
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\managers.py", line 805, in _connect
    conn = self._Client(self._token.address, authkey=self._authkey)
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 499, in Client
    c = PipeClient(address)
  File "C:\Users\Jackson\anaconda3\Lib\multiprocessing\connection.py", line 701, in PipeClient
    _winapi.WaitNamedPipe(address, 1000)
FileNotFoundError: [WinError 2] The system cannot find the file specified
2023-10-24 02:52:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 27995,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 3949410,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 13.87832,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 24, 2, 52, 40, 684184),
 'httpcompression/response_bytes': 18136370,
 'httpcompression/response_count': 50,
 'log_count/ERROR': 51,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'spider_exceptions/EOFError': 1,
 'spider_exceptions/FileNotFoundError': 49,
 'start_time': datetime.datetime(2023, 10, 24, 2, 52, 26, 805864)}
2023-10-24 02:52:40 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-24 02:53:47 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 02:53:47 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 02:53:47 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 02:53:47 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 02:53:47 [scrapy.extensions.telnet] INFO: Telnet Password: c41d9c7923c81ce4
2023-10-24 02:53:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 02:53:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 02:53:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 02:53:47 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 02:53:47 [scrapy.core.engine] INFO: Spider opened
2023-10-24 02:53:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 02:53:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 02:53:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=20> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=22> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=21> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=23> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=24> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=25> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=26> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=27> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=28> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=29> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=30> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=31> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=32> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=33> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=35> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=34> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=37> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=36> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=38> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=39> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=41> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=40> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=42> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=44> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=43> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=45> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:53:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=46> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:54:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=47> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:54:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=48> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:54:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=49> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:54:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-sale/?includePropertiesWithin=includesurrounding&propertyTypes=retail%2Cland-development%2Chotel-motel-leisure%2Cindustrial-warehouse%2Coffices%2Cshowrooms-bulky-goods&maxPrice=5000000&minPrice=100000&minFloorArea=50&minSiteArea=200&numParkingSpaces=3&page=50> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 02:54:00 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-24 02:54:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 29698,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 3913133,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 13.353105,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 24, 2, 54, 0, 794794),
 'httpcompression/response_bytes': 18623381,
 'httpcompression/response_count': 50,
 'item_scraped_count': 192,
 'log_count/ERROR': 31,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 19,
 'request_depth_max': 1,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'spider_exceptions/KeyError': 31,
 'start_time': datetime.datetime(2023, 10, 24, 2, 53, 47, 441689)}
2023-10-24 02:54:00 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-24 03:16:40 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 03:16:40 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 03:16:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 03:16:40 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 03:16:40 [scrapy.extensions.telnet] INFO: Telnet Password: 6ec5e4c8f5c6e849
2023-10-24 03:16:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 03:16:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 03:16:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 03:16:40 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 03:16:40 [scrapy.core.engine] INFO: Spider opened
2023-10-24 03:16:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 03:16:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 03:16:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=36> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=38> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=37> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=39> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=40> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=41> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=42> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=43> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=44> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=46> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=45> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=47> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=49> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=48> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.realcommercial.com.au/for-lease/?includePropertiesWithin=includesurrounding&maxPrice=35000&minPrice=30000&page=50> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\defer.py", line 257, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\python.py", line 312, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 28, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 353, in <genexpr>
    return (self._set_referer(r, response) for r in result or ())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 27, in <genexpr>
    return (r for r in result or () if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 31, in <genexpr>
    return (r for r in result or () if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\core\spidermw.py", line 104, in process_sync
    for r in iterable:
  File "D:\Project\scrapping\pyqt-scrapy\scraps\spiders\scraps.py", line 37, in parse
    items['title'] = item['title']
                     ~~~~^^^^^^^^^
KeyError: 'title'
2023-10-24 03:16:52 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-24 03:16:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 21267,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 3817741,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 12.43017,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 24, 3, 16, 52, 730155),
 'httpcompression/response_bytes': 17407705,
 'httpcompression/response_count': 50,
 'item_scraped_count': 356,
 'log_count/ERROR': 15,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 35,
 'request_depth_max': 1,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'spider_exceptions/KeyError': 15,
 'start_time': datetime.datetime(2023, 10, 24, 3, 16, 40, 299985)}
2023-10-24 03:16:52 [scrapy.core.engine] INFO: Spider closed (finished)
2023-10-24 03:19:34 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 03:19:34 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 03:19:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 03:19:34 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 03:19:34 [scrapy.extensions.telnet] INFO: Telnet Password: 075ada4189015eec
2023-10-24 03:19:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 03:19:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 03:19:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 03:19:34 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 03:19:34 [scrapy.core.engine] INFO: Spider opened
2023-10-24 03:19:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 03:19:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 03:19:47 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scraps)
2023-10-24 03:19:47 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.4, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.10.0, Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 23.2.0 (OpenSSL 3.0.10 1 Aug 2023), cryptography 41.0.3, Platform Windows-10-10.0.19045-SP0
2023-10-24 03:19:47 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scraps',
 'LOG_FILE': 'output.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scraps.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['scraps.spiders']}
2023-10-24 03:19:47 [py.warnings] WARNING: C:\Users\Jackson\anaconda3\Lib\site-packages\scrapy\utils\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.

It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.

See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.
  return cls(crawler)

2023-10-24 03:19:47 [scrapy.extensions.telnet] INFO: Telnet Password: fff2f445b24a8940
2023-10-24 03:19:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2023-10-24 03:19:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2023-10-24 03:19:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2023-10-24 03:19:47 [scrapy.middleware] INFO: Enabled item pipelines:
['scraps.pipelines.ChanelPipeline']
2023-10-24 03:19:47 [scrapy.core.engine] INFO: Spider opened
2023-10-24 03:19:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2023-10-24 03:19:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2023-10-24 03:19:59 [scrapy.core.engine] INFO: Closing spider (finished)
2023-10-24 03:19:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 19716,
 'downloader/request_count': 51,
 'downloader/request_method_count/GET': 51,
 'downloader/response_bytes': 3944105,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 51,
 'elapsed_time_seconds': 11.488783,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2023, 10, 24, 3, 19, 59, 445498),
 'httpcompression/response_bytes': 18024360,
 'httpcompression/response_count': 50,
 'item_scraped_count': 500,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 48,
 'request_depth_max': 1,
 'response_received_count': 51,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2023, 10, 24, 3, 19, 47, 956715)}
2023-10-24 03:19:59 [scrapy.core.engine] INFO: Spider closed (finished)
